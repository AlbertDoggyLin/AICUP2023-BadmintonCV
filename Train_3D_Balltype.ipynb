{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pytorch_toolbelt import losses as L\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493426d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model_name = 'csn_r101'\n",
    "        self.model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n",
    "        self.model.blocks[-1].proj= nn.Linear(in_features=2048, out_features=12, bias=True)\n",
    "#         self.model.projection.model= nn.Linear(in_features=2048, out_features=cls, bias=True)\n",
    "        \n",
    "    def forward(self, image):\n",
    "#         x= nn.functional.interpolate(image, \n",
    "#                                      size=(32,CFG['img_size'],CFG['img_size']), \n",
    "#                                      scale_factor=None, \n",
    "#                                      mode='nearest', \n",
    "#                                      align_corners=None)\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "    \n",
    "# print(torch.hub.list('facebookresearch/pytorchvideo'))\n",
    "# model= Customize_Model()\n",
    "# x= torch.rand(1,3,16,512,512)\n",
    "# x= model(x)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit= 10,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.7),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "\n",
    "def get_resize_transform(height, width):\n",
    "    return A.Compose([\n",
    "        A.Resize(width, height, p=1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(path):\n",
    "    imgs= []\n",
    "    cap= cv2.VideoCapture(path)\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        if not ret: break\n",
    "        img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        imgs.append(img)\n",
    "    ## resize z-axis\n",
    "    imgs= np.array(imgs)\n",
    "    imgs= get_resize_transform(imgs.shape[1], CFG[\"depth\"])(image= imgs)['image']\n",
    "    \n",
    "    return np.array(imgs) ## (img_len, H, W)\n",
    "\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.is_train= is_train\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        balltype= int(data['BallType'])  ## class 0 is empty\n",
    "        cls= [0]*10\n",
    "        cls[balltype]= 1\n",
    "        balltype= np.array(cls)\n",
    "        landing= np.asarray([ data['LandingX'], data['LandingY'] ], dtype= np.int).tolist()\n",
    "        \n",
    "        img= read_video(data['image_path'])\n",
    "        img = img.transpose(1,2,0)\n",
    "        \n",
    "        if self.transforms:\n",
    "            while True:\n",
    "                trans= self.transforms(image=img, keypoints=[landing])\n",
    "                aug_img= trans[\"image\"]\n",
    "                aug_landing= trans[\"keypoints\"]\n",
    "                if len(aug_landing)!=0: \n",
    "                    img= aug_img\n",
    "                    landing= aug_landing\n",
    "                    break\n",
    "        \n",
    "        ## convert to 3 channel\n",
    "        img= img.unsqueeze(dim=0)\n",
    "        img= img.expand(3,img.shape[1],img.shape[2],img.shape[3])\n",
    "        \n",
    "        label= np.append(balltype, landing[0], axis=0)\n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'balltype': torch.tensor(balltype, dtype=torch.long),\n",
    "            'landing': torch.tensor(landing[0], dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CE= nn.CrossEntropyLoss(weight= None, label_smoothing=0.05)\n",
    "        self.mse= nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss_cls= self.CE(y_pred[..., :-2], y_true[..., :-2])\n",
    "#         loss_reg= self.mse(y_pred[..., -2:], y_true[..., -2:])\n",
    "        loss= loss_cls #+ loss_reg\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "\n",
    "def AUC_score(all_pred, all_label):\n",
    "    auc= roc_auc_score(all_label, all_pred, multi_class='ovo')\n",
    "    return auc\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels[...,1:-2].cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds[...,1:-2].cpu().softmax(dim=-1).numpy())\n",
    "        \n",
    "    \n",
    "    ## caculate metrics\n",
    "    all_label= np.array(all_label).argmax(-1)\n",
    "    all_pred= np.array(all_pred)\n",
    "    \n",
    "    acc= Accuracy(all_pred, all_label)\n",
    "    print(f'accuracy: {acc}')\n",
    "    recall= Mean_Recall(all_pred, all_label)\n",
    "    print(f'mean_recall: {recall}')\n",
    "    auc= AUC_score(all_pred, all_label)\n",
    "    print(f'AUC: {auc}')\n",
    "    \n",
    "    score= auc\n",
    "    return np.mean(ep_loss), score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 3,\n",
    "    'epoch': 50,\n",
    "    \n",
    "    'img_size': 512,\n",
    "    'depth': 32,\n",
    "    \n",
    "    'batch_size': 1,\n",
    "    'gradient_accumulation': 1,\n",
    "    \n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    \n",
    "    'load_model': False, #'./test_model/hitframe/cv1_best.pth'\n",
    "    'save_model': './train_model'\n",
    "}\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/train_balltype_land.csv')\n",
    "df['BallType'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['HitFrame']!=0]\n",
    "train_dataset= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "new_df= ''\n",
    "N= 300\n",
    "for l  in range(1,10):\n",
    "    temp_df= train_dataset[train_dataset['BallType']==l]\n",
    "    try: temp_df= temp_df.sample(n=N, replace=False, random_state=1)\n",
    "    except: temp_df= temp_df.sample(n=N, replace=True, random_state=1)\n",
    "    if len(new_df)==0: new_df= temp_df\n",
    "    else: new_df= pd.concat([new_df, temp_df], axis=0)\n",
    "train_dataset= new_df.reset_index(drop=True)\n",
    "\n",
    "valid_dataset= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_dataset)}')\n",
    "print(f'valid dataset: {len(valid_dataset)}')\n",
    "\n",
    "train_dataset= Customize_Dataset(train_dataset.iloc[:], get_train_transform(CFG['img_size']), is_train=True)\n",
    "valid_dataset= Customize_Dataset(valid_dataset.iloc[:], get_test_transform(CFG['img_size']), is_train=False)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size=CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5564f00",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data['image']\n",
    "landing= data['landing'].numpy().astype(np.int)\n",
    "del data['image']\n",
    "print(img.shape)\n",
    "print(data)\n",
    "img= img[:,20].permute(1,2,0).numpy()\n",
    "img= img*255\n",
    "img= img.astype(np.uint8).copy()\n",
    "cv2.circle(img, landing, radius=7, color=(255, 0, 0), thickness=-1)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Customize_Model()\n",
    "model.to('cuda')\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 0\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'\\nep: {ep}')\n",
    "    \n",
    "    train_loss= train_epoch(train_loader, model, criterion, optimizer)\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model, criterion)\n",
    "    print(f'train loss: {round(train_loss, 5)}')\n",
    "    print(f'valid loss: {round(valid_loss, 5)}, valid_acc: {round(valid_acc, 5)}')\n",
    "    \n",
    "    if valid_acc >= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        print(f'model save at score: {round(best_score, 5)}')\n",
    "        \n",
    "    ## save model every epoch\n",
    "    torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "216054eb",
   "metadata": {},
   "source": [
    "csn, s512_d32, acc= 0.83"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
