{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c42fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "def get_resize_transform(height, width):\n",
    "    return A.Compose([\n",
    "        A.Resize(width, height, p=1),\n",
    "    ])\n",
    "\n",
    "\n",
    "def read_video(path):\n",
    "    imgs= []\n",
    "    cap= cv2.VideoCapture(path)\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        if not ret: break\n",
    "        img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        imgs.append(img)\n",
    "    ## resize z-axis\n",
    "    imgs= np.array(imgs)\n",
    "    imgs= get_resize_transform(imgs.shape[1], CFG[\"depth\"])(image= imgs)['image']\n",
    "    \n",
    "    return np.array(imgs) ## (img_len, H, W)\n",
    "\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.is_train= is_train\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img= read_video(data['image_path'])\n",
    "        img = img.transpose(1,2,0)\n",
    "        \n",
    "        if self.transforms:\n",
    "            trans= self.transforms(image=img)\n",
    "            img= trans[\"image\"]\n",
    "        \n",
    "        ## convert to 3 channel\n",
    "        img= img.unsqueeze(dim=0)\n",
    "        img= img.expand(3,img.shape[1],img.shape[2],img.shape[3])\n",
    "        \n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9004c",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ee22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'img_size': 512,\n",
    "    'depth': 32,\n",
    "    \n",
    "    'TTA': 2,  ## disable TTA= 1\n",
    "    'model': [\n",
    "        './test_model/ball_type/csn_img512_d32/cv0_best.pth',\n",
    "        './test_model/ball_type/csn_img512_d32/cv2_best.pth',\n",
    "    ]\n",
    "}\n",
    "CFG['model']= [ torch.load(m, map_location= 'cuda:0') for m in CFG['model'] ]\n",
    "print(f\"length of model: {len(CFG['model'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0061056",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths= glob.glob('Data/val_test_balltype_landing/**/*mp4', recursive=True)\n",
    "paths= sorted(paths, key= lambda x:int(x.split('_')[-1].split('.')[0]))\n",
    "test_df= pd.DataFrame()\n",
    "test_df['image_path']= paths\n",
    "print(f'valid dataset: {len(test_df)}')\n",
    "\n",
    "valid_dataset= Customize_Dataset(test_df.iloc[:].reset_index(drop=True), get_test_transform(CFG['img_size']))\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, img):\n",
    "    \n",
    "    img= torch.unsqueeze(img, 0).cuda()\n",
    "    for i, m in enumerate(model):\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            imgs= torch.cat([img, img.flip(-1), img.flip(-2), img.flip(-1).flip(-2)], dim=0)\n",
    "            pred= m(imgs[:CFG['TTA']])\n",
    "            pred= pred.mean(dim=0)\n",
    "                \n",
    "        if i==0: preds= pred[:-2].softmax(dim=-1)\n",
    "        else: preds+= pred[:-2].softmax(dim=-1)\n",
    "            \n",
    "    pred= preds/len(model)\n",
    "    pred= pred.cpu().numpy().tolist()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79354f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submision= pd.read_csv('submission/submission_val_test.csv')\n",
    "count= 0\n",
    "for i, data in enumerate(tqdm(valid_loader)):\n",
    "    for j in range(len(data['image'])):\n",
    "        imgs= data['image'][j]\n",
    "        pred= inference(CFG['model'], imgs)\n",
    "        \n",
    "        submision.loc[count, 'BallType']= int( np.array(pred).argmax(0) )\n",
    "        count+= 1\n",
    "    \n",
    "submision.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59520ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv('submission.csv', index=False)\n",
    "submision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
